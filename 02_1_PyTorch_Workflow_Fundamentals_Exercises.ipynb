{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEF5X2rKSgEoqJHFDpzZgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capabledjay/Deep_Learning_With_Pytorch/blob/main/02_1_PyTorch_Workflow_Fundamentals_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a straight line dataset using the linear regression formula (weight * X + bias).\n",
        "  * Set weight=0.3 and bias=0.9 there should be at least 100 datapoints total.\n",
        "  * Split the data into 80% training, 20% testing.\n",
        "  * Plot the training and testing data so it becomes visual."
      ],
      "metadata": {
        "id": "iuMYyHq_8Udo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Build a PyTorch model by subclassing nn.Module.\n",
        "  * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for weights and one for bias.\n",
        "  * Implement the `forward()` method to compute the linear regression function you used to create the dataset in 1.\n",
        "  * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
        "\n",
        "  \n",
        "Note: If you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can."
      ],
      "metadata": {
        "id": "LcjRemND8dv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a loss function and optimizer using nn.L1Loss() and torch.optim.SGD(params, lr) respectively.\n",
        "  * Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters from the model you created in 2.\n",
        "  * Write a training loop to perform the appropriate training steps for 300 epochs.\n",
        "  * The training loop should test the model on the test dataset every 20 epochs."
      ],
      "metadata": {
        "id": "MEU_AsEo8kUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Make predictions with the trained model on the test data.\n",
        "  * Visualize these predictions against the original training and testing data (note: you may need to make sure the predictions are not on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)."
      ],
      "metadata": {
        "id": "hLNnUOkH9xj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Save your trained model's state_dict() to file.\n",
        "  * Create a new instance of your model class you made in 2. and load in the state_dict() you just saved to it.\n",
        "  * Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."
      ],
      "metadata": {
        "id": "u7cZ_KU292tL"
      }
    }
  ]
}